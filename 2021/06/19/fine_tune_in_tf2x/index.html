<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Eager Few Shot Object Detection ColabWelcome to the Eager Few Shot Object Detection Colab ‚Äî in this colab we demonstrate fine tuning of a (TF2 friendly) RetinaNet architecture on very few examples of">
<meta property="og:type" content="article">
<meta property="og:title" content="Fine Tune in Tensorflow 2.x">
<meta property="og:url" content="http://example.com/2021/06/19/fine_tune_in_tf2x/index.html">
<meta property="og:site_name" content="ÂçäÊùØËå∂ÁöÑÂ∞èÈÖíÊùØ">
<meta property="og:description" content="Eager Few Shot Object Detection ColabWelcome to the Eager Few Shot Object Detection Colab ‚Äî in this colab we demonstrate fine tuning of a (TF2 friendly) RetinaNet architecture on very few examples of">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2021/06/19/fine_tune_in_tf2x/interactive_eager_few_shot_od_training_colab_9_0.png">
<meta property="og:image" content="http://example.com/2021/06/19/fine_tune_in_tf2x/interactive_eager_few_shot_od_training_colab_17_0.png">
<meta property="og:image" content="http://example.com/2021/06/19/fine_tune_in_tf2x/interactive_eager_few_shot_od_training_colab_25_1.gif">
<meta property="article:published_time" content="2021-06-19T07:39:38.000Z">
<meta property="article:modified_time" content="2021-06-19T07:54:00.284Z">
<meta property="article:author" content="Young Times">
<meta property="article:tag" content="Ëá™Âä®È©æÈ©∂">
<meta property="article:tag" content="Êú∫Âô®Â≠¶‰π†">
<meta property="article:tag" content="Ê∑±Â∫¶Â≠¶‰π†">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2021/06/19/fine_tune_in_tf2x/interactive_eager_few_shot_od_training_colab_9_0.png">

<link rel="canonical" href="http://example.com/2021/06/19/fine_tune_in_tf2x/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Fine Tune in Tensorflow 2.x | ÂçäÊùØËå∂ÁöÑÂ∞èÈÖíÊùØ</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="ÂàáÊç¢ÂØºËà™Ê†è">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">ÂçäÊùØËå∂ÁöÑÂ∞èÈÖíÊùØ</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>È¶ñÈ°µ</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>ÂÖ≥‰∫é</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Ê†áÁ≠æ</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>ÂàÜÁ±ª</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>ÂΩíÊ°£</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>ÊêúÁ¥¢
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="ÊêúÁ¥¢..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/06/19/fine_tune_in_tf2x/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/header.jpg">
      <meta itemprop="name" content="Young Times">
      <meta itemprop="description" content="Ë∑ØË¶Å‰∏ÄÊ≠•‰∏ÄÊ≠•ÁöÑËµ∞">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ÂçäÊùØËå∂ÁöÑÂ∞èÈÖíÊùØ">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Fine Tune in Tensorflow 2.x
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">ÂèëË°®‰∫é</span>
              

              <time title="ÂàõÂª∫Êó∂Èó¥Ôºö2021-06-19 15:39:38 / ‰øÆÊîπÊó∂Èó¥Ôºö15:54:00" itemprop="dateCreated datePublished" datetime="2021-06-19T15:39:38+08:00">2021-06-19</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">ÂàÜÁ±ª‰∫é</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/" itemprop="url" rel="index"><span itemprop="name">Ëá™Âä®È©æÈ©∂</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="ÈòÖËØªÊ¨°Êï∞" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">ÈòÖËØªÊ¨°Êï∞Ôºö</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">ValineÔºö</span>
    
    <a title="valine" href="/2021/06/19/fine_tune_in_tf2x/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/06/19/fine_tune_in_tf2x/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="Êú¨ÊñáÂ≠óÊï∞">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">Êú¨ÊñáÂ≠óÊï∞Ôºö</span>
              <span>47k</span>
            </span>
            <span class="post-meta-item" title="ÈòÖËØªÊó∂Èïø">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">ÈòÖËØªÊó∂Èïø &asymp;</span>
              <span>43 ÂàÜÈíü</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="Eager-Few-Shot-Object-Detection-Colab"><a href="#Eager-Few-Shot-Object-Detection-Colab" class="headerlink" title="Eager Few Shot Object Detection Colab"></a>Eager Few Shot Object Detection Colab</h1><p>Welcome to the Eager Few Shot Object Detection Colab ‚Äî in this colab we demonstrate fine tuning of a (TF2 friendly) RetinaNet architecture on very few examples of a novel class after initializing from a pre-trained COCO checkpoint.<br>Training runs in eager mode.</p>
<p>Estimated time to run through this colab (with GPU): &lt; 5 minutes.</p>
<span id="more"></span>

<h2 id="Imports"><a href="#Imports" class="headerlink" title="Imports"></a>Imports</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip install -U --pre tensorflow&#x3D;&#x3D;&quot;2.2.0&quot;</span><br></pre></td></tr></table></figure>

<pre><code>Collecting tensorflow==2.2.0
Downloading https://files.pythonhosted.org/packages/4c/1a/0d79814736cfecc825ab8094b39648cc9c46af7af1bae839928acb73b4dd/tensorflow-2.2.0-cp37-cp37m-manylinux2010_x86_64.whl (516.2MB)
‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 516.2MB 35kB/s 
Requirement already satisfied, skipping upgrade: google-pasta&gt;=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.2.0)
Requirement already satisfied, skipping upgrade: wrapt&gt;=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.12.1)
Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.6.3)
Requirement already satisfied, skipping upgrade: numpy&lt;2.0,&gt;=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.19.5)
Collecting tensorboard&lt;2.3.0,&gt;=2.2.0
Downloading https://files.pythonhosted.org/packages/1d/74/0a6fcb206dcc72a6da9a62dd81784bfdbff5fedb099982861dc2219014fb/tensorboard-2.2.2-py3-none-any.whl (3.0MB)
|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.0MB 38.4MB/s 
Requirement already satisfied, skipping upgrade: keras-preprocessing&gt;=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.1.2)
Requirement already satisfied, skipping upgrade: protobuf&gt;=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (3.12.4)
Requirement already satisfied, skipping upgrade: grpcio&gt;=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.34.1)
Requirement already satisfied, skipping upgrade: wheel&gt;=0.26; python_version &gt;= &quot;3&quot; in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.36.2)
Requirement already satisfied, skipping upgrade: absl-py&gt;=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.12.0)
Requirement already satisfied, skipping upgrade: termcolor&gt;=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.1.0)
Collecting h5py&lt;2.11.0,&gt;=2.10.0
Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)
|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.9MB 7.7MB/s 
Collecting gast==0.3.3
Downloading https://files.pythonhosted.org/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl
Requirement already satisfied, skipping upgrade: six&gt;=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.15.0)
Requirement already satisfied, skipping upgrade: opt-einsum&gt;=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (3.3.0)
Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version &gt;= &quot;3&quot; in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.4.1)
Collecting tensorflow-estimator&lt;2.3.0,&gt;=2.2.0
Downloading https://files.pythonhosted.org/packages/a4/f5/926ae53d6a226ec0fda5208e0e581cffed895ccc89e36ba76a8e60895b78/tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454kB)
|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 460kB 52.4MB/s 
Requirement already satisfied, skipping upgrade: google-auth-oauthlib&lt;0.5,&gt;=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard&lt;2.3.0,&gt;=2.2.0-&gt;tensorflow==2.2.0) (0.4.4)
Requirement already satisfied, skipping upgrade: google-auth&lt;2,&gt;=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard&lt;2.3.0,&gt;=2.2.0-&gt;tensorflow==2.2.0) (1.31.0)
Requirement already satisfied, skipping upgrade: requests&lt;3,&gt;=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard&lt;2.3.0,&gt;=2.2.0-&gt;tensorflow==2.2.0) (2.23.0)
Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit&gt;=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard&lt;2.3.0,&gt;=2.2.0-&gt;tensorflow==2.2.0) (1.8.0)
Requirement already satisfied, skipping upgrade: setuptools&gt;=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard&lt;2.3.0,&gt;=2.2.0-&gt;tensorflow==2.2.0) (57.0.0)
Requirement already satisfied, skipping upgrade: werkzeug&gt;=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard&lt;2.3.0,&gt;=2.2.0-&gt;tensorflow==2.2.0) (1.0.1)
Requirement already satisfied, skipping upgrade: markdown&gt;=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard&lt;2.3.0,&gt;=2.2.0-&gt;tensorflow==2.2.0) (3.3.4)
Requirement already satisfied, skipping upgrade: requests-oauthlib&gt;=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard&lt;2.3.0,&gt;=2.2.0-&gt;tensorflow==2.2.0) (1.3.0)
Requirement already satisfied, skipping upgrade: pyasn1-modules&gt;=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard&lt;2.3.0,&gt;=2.2.0-&gt;tensorflow==2.2.0) (0.2.8)
Requirement already satisfied, skipping upgrade: cachetools&lt;5.0,&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard&lt;2.3.0,&gt;=2.2.0-&gt;tensorflow==2.2.0) (4.2.2)
Requirement already satisfied, skipping upgrade: rsa&lt;5,&gt;=3.1.4; python_version &gt;= &quot;3.6&quot; in /usr/local/lib/python3.7/dist-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard&lt;2.3.0,&gt;=2.2.0-&gt;tensorflow==2.2.0) (4.7.2)
Requirement already satisfied, skipping upgrade: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&lt;2.3.0,&gt;=2.2.0-&gt;tensorflow==2.2.0) (2.10)
Requirement already satisfied, skipping upgrade: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&lt;2.3.0,&gt;=2.2.0-&gt;tensorflow==2.2.0) (2021.5.30)
Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&lt;2.3.0,&gt;=2.2.0-&gt;tensorflow==2.2.0) (1.24.3)
Requirement already satisfied, skipping upgrade: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&lt;2.3.0,&gt;=2.2.0-&gt;tensorflow==2.2.0) (3.0.4)
Requirement already satisfied, skipping upgrade: importlib-metadata; python_version &lt; &quot;3.8&quot; in /usr/local/lib/python3.7/dist-packages (from markdown&gt;=2.6.8-&gt;tensorboard&lt;2.3.0,&gt;=2.2.0-&gt;tensorflow==2.2.0) (4.5.0)
Requirement already satisfied, skipping upgrade: oauthlib&gt;=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard&lt;2.3.0,&gt;=2.2.0-&gt;tensorflow==2.2.0) (3.1.1)
Requirement already satisfied, skipping upgrade: pyasn1&lt;0.5.0,&gt;=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard&lt;2.3.0,&gt;=2.2.0-&gt;tensorflow==2.2.0) (0.4.8)
Requirement already satisfied, skipping upgrade: typing-extensions&gt;=3.6.4; python_version &lt; &quot;3.8&quot; in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version &lt; &quot;3.8&quot;-&gt;markdown&gt;=2.6.8-&gt;tensorboard&lt;2.3.0,&gt;=2.2.0-&gt;tensorflow==2.2.0) (3.7.4.3)
Requirement already satisfied, skipping upgrade: zipp&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version &lt; &quot;3.8&quot;-&gt;markdown&gt;=2.6.8-&gt;tensorboard&lt;2.3.0,&gt;=2.2.0-&gt;tensorflow==2.2.0) (3.4.1)
Installing collected packages: tensorboard, h5py, gast, tensorflow-estimator, tensorflow
  Found existing installation: tensorboard 2.5.0
    Uninstalling tensorboard-2.5.0:
      Successfully uninstalled tensorboard-2.5.0
  Found existing installation: h5py 3.1.0
    Uninstalling h5py-3.1.0:
      Successfully uninstalled h5py-3.1.0
  Found existing installation: gast 0.4.0
    Uninstalling gast-0.4.0:
      Successfully uninstalled gast-0.4.0
  Found existing installation: tensorflow-estimator 2.5.0
    Uninstalling tensorflow-estimator-2.5.0:
      Successfully uninstalled tensorflow-estimator-2.5.0
  Found existing installation: tensorflow 2.5.0
    Uninstalling tensorflow-2.5.0:
      Successfully uninstalled tensorflow-2.5.0
Successfully installed gast-0.3.3 h5py-2.10.0 tensorboard-2.2.2 tensorflow-2.2.0 tensorflow-estimator-2.2.0
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pathlib</span><br><span class="line"></span><br><span class="line"><span class="comment"># Clone the tensorflow models repository if it doesn&#x27;t already exist</span></span><br><span class="line"><span class="keyword">if</span> <span class="string">&quot;models&quot;</span> <span class="keyword">in</span> pathlib.Path.cwd().parts:</span><br><span class="line">  <span class="keyword">while</span> <span class="string">&quot;models&quot;</span> <span class="keyword">in</span> pathlib.Path.cwd().parts:</span><br><span class="line">    os.chdir(<span class="string">&#x27;..&#x27;</span>)</span><br><span class="line"><span class="keyword">elif</span> <span class="keyword">not</span> pathlib.Path(<span class="string">&#x27;models&#x27;</span>).exists():</span><br><span class="line">  !git clone --depth <span class="number">1</span> https://github.com/tensorflow/models</span><br></pre></td></tr></table></figure>

<pre><code>Cloning into &#39;models&#39;...
remote: Enumerating objects: 2713, done.[K
remote: Counting objects: 100% (2713/2713), done.[K
remote: Compressing objects: 100% (2248/2248), done.[K
remote: Total 2713 (delta 692), reused 1250 (delta 431), pack-reused 0[K
Receiving objects: 100% (2713/2713), 32.69 MiB | 22.31 MiB/s, done.
Resolving deltas: 100% (692/692), done.
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Install the Object Detection API</span></span><br><span class="line">%%bash</span><br><span class="line">cd models/research/</span><br><span class="line">protoc object_detection/protos/*.proto --python_out=.</span><br><span class="line">cp object_detection/packages/tf2/setup.py .</span><br><span class="line">python -m pip install .</span><br></pre></td></tr></table></figure>

<pre><code>Processing /content/models/research
Collecting avro-python3
  Downloading https://files.pythonhosted.org/packages/cc/97/7a6970380ca8db9139a3cc0b0e3e0dd3e4bc584fb3644e1d06e71e1a55f0/avro-python3-1.10.2.tar.gz
Collecting apache-beam
  Downloading https://files.pythonhosted.org/packages/ac/c9/395a9759dfbf9e87203a69c33b2e94f10d566d9391bddb6f99facafe64c3/apache_beam-2.30.0-cp37-cp37m-manylinux2010_x86_64.whl (9.6MB)
Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)
Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)
Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)
Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.23)
Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)
Collecting tf-slim
  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)
Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)
Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.2)
Collecting lvis
  Downloading https://files.pythonhosted.org/packages/72/b6/1992240ab48310b5360bfdd1d53163f43bb97d90dc5dc723c67d41c38e78/lvis-0.5.3-py3-none-any.whl
Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)
Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)
Collecting tf-models-official
  Downloading https://files.pythonhosted.org/packages/96/08/81bbc275e8e9c6d1e03dd26daec3a67f45e6322804cbce3d51f93eae1961/tf_models_official-2.5.0-py2.py3-none-any.whl (1.6MB)
Requirement already satisfied: crcmod&lt;2.0,&gt;=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam-&gt;object-detection==0.1) (1.7)
Requirement already satisfied: pymongo&lt;4.0.0,&gt;=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam-&gt;object-detection==0.1) (3.11.4)
Requirement already satisfied: protobuf&lt;4,&gt;=3.12.2 in /usr/local/lib/python3.7/dist-packages (from apache-beam-&gt;object-detection==0.1) (3.12.4)
Requirement already satisfied: pyarrow&lt;4.0.0,&gt;=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam-&gt;object-detection==0.1) (3.0.0)
Collecting hdfs&lt;3.0.0,&gt;=2.1.0
  Downloading https://files.pythonhosted.org/packages/08/f7/4c3fad73123a24d7394b6f40d1ec9c1cbf2e921cfea1797216ffd0a51fb1/hdfs-2.6.0-py3-none-any.whl
Requirement already satisfied: pydot&lt;2,&gt;=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam-&gt;object-detection==0.1) (1.3.0)
Requirement already satisfied: oauth2client&lt;5,&gt;=2.0.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam-&gt;object-detection==0.1) (4.1.3)
Collecting fastavro&lt;2,&gt;=0.21.4
  Downloading https://files.pythonhosted.org/packages/52/d1/8f5c8611026f0ddcd86a8e2f965998e0c159af980c31efba72342c69f3e4/fastavro-1.4.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2MB)
Collecting requests&lt;3.0.0,&gt;=2.24.0
  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)
Collecting dill&lt;0.3.2,&gt;=0.3.1.1
  Downloading https://files.pythonhosted.org/packages/c7/11/345f3173809cea7f1a193bfbf02403fff250a3360e0e118a1630985e547d/dill-0.3.1.1.tar.gz (151kB)
Requirement already satisfied: numpy&lt;1.21.0,&gt;=1.14.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam-&gt;object-detection==0.1) (1.19.5)
Collecting future&lt;1.0.0,&gt;=0.18.2
  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)
Requirement already satisfied: httplib2&lt;0.20.0,&gt;=0.8 in /usr/local/lib/python3.7/dist-packages (from apache-beam-&gt;object-detection==0.1) (0.17.4)
Requirement already satisfied: grpcio&lt;2,&gt;=1.29.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam-&gt;object-detection==0.1) (1.34.1)
Requirement already satisfied: pytz&gt;=2018.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam-&gt;object-detection==0.1) (2018.9)
Requirement already satisfied: typing-extensions&lt;3.8.0,&gt;=3.7.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam-&gt;object-detection==0.1) (3.7.4.3)
Requirement already satisfied: python-dateutil&lt;3,&gt;=2.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam-&gt;object-detection==0.1) (2.8.1)
Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;object-detection==0.1) (2.4.7)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;object-detection==0.1) (1.3.1)
Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;object-detection==0.1) (0.10.0)
Requirement already satisfied: absl-py&gt;=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf-slim-&gt;object-detection==0.1) (0.12.0)
Requirement already satisfied: setuptools&gt;=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools-&gt;object-detection==0.1) (57.0.0)
Requirement already satisfied: opencv-python&gt;=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis-&gt;object-detection==0.1) (4.1.2.30)
Requirement already satisfied: tensorflow-hub&gt;=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official-&gt;object-detection==0.1) (0.12.0)
Requirement already satisfied: kaggle&gt;=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official-&gt;object-detection==0.1) (1.5.12)
Collecting pyyaml&gt;=5.1
  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)
Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official-&gt;object-detection==0.1) (0.4.0)
Collecting tensorflow-addons
  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)
Collecting tensorflow-model-optimization&gt;=0.4.1
  Downloading https://files.pythonhosted.org/packages/78/8f/f6969dc64709c5c5e22cfd7057a83adbc927e6855a431b234168222cbf03/tensorflow_model_optimization-0.6.0-py2.py3-none-any.whl (211kB)
Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official-&gt;object-detection==0.1) (4.0.1)
Collecting tensorflow&gt;=2.5.0
  Downloading https://files.pythonhosted.org/packages/aa/fd/993aa1333eb54d9f000863fe8ec61e41d12eb833dea51484c76c038718b5/tensorflow-2.5.0-cp37-cp37m-manylinux2010_x86_64.whl (454.3MB)
Collecting seqeval
  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)
Requirement already satisfied: google-cloud-bigquery&gt;=0.31.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official-&gt;object-detection==0.1) (1.21.0)
Requirement already satisfied: psutil&gt;=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official-&gt;object-detection==0.1) (5.4.8)
Collecting opencv-python-headless
  Downloading https://files.pythonhosted.org/packages/c3/35/bfc76533f2274cd3da4e2cf255cd13ab9d7f6fc8990c06911e7f8fcc2130/opencv_python_headless-4.5.2.54-cp37-cp37m-manylinux2014_x86_64.whl (38.2MB)
Collecting sacrebleu
  Downloading https://files.pythonhosted.org/packages/7e/57/0c7ca4e31a126189dab99c19951910bd081dea5bbd25f24b77107750eae7/sacrebleu-1.5.1-py3-none-any.whl (54kB)
Collecting sentencepiece
  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)
Requirement already satisfied: google-api-python-client&gt;=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official-&gt;object-detection==0.1) (1.12.8)
Collecting py-cpuinfo&gt;=3.3.0
  Downloading https://files.pythonhosted.org/packages/e6/ba/77120e44cbe9719152415b97d5bfb29f4053ee987d6cb63f55ce7d50fadc/py-cpuinfo-8.0.0.tar.gz (99kB)
Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs&lt;3.0.0,&gt;=2.1.0-&gt;apache-beam-&gt;object-detection==0.1) (0.6.2)
Requirement already satisfied: pyasn1&gt;=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client&lt;5,&gt;=2.0.1-&gt;apache-beam-&gt;object-detection==0.1) (0.4.8)
Requirement already satisfied: pyasn1-modules&gt;=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client&lt;5,&gt;=2.0.1-&gt;apache-beam-&gt;object-detection==0.1) (0.2.8)
Requirement already satisfied: rsa&gt;=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client&lt;5,&gt;=2.0.1-&gt;apache-beam-&gt;object-detection==0.1) (4.7.2)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3.0.0,&gt;=2.24.0-&gt;apache-beam-&gt;object-detection==0.1) (1.24.3)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3.0.0,&gt;=2.24.0-&gt;apache-beam-&gt;object-detection==0.1) (2021.5.30)
Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3.0.0,&gt;=2.24.0-&gt;apache-beam-&gt;object-detection==0.1) (2.10)
Requirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3.0.0,&gt;=2.24.0-&gt;apache-beam-&gt;object-detection==0.1) (3.0.4)
Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle&gt;=1.3.9-&gt;tf-models-official-&gt;object-detection==0.1) (4.41.1)
Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle&gt;=1.3.9-&gt;tf-models-official-&gt;object-detection==0.1) (5.0.2)
Requirement already satisfied: typeguard&gt;=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons-&gt;tf-models-official-&gt;object-detection==0.1) (2.7.1)
Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization&gt;=0.4.1-&gt;tf-models-official-&gt;object-detection==0.1) (0.1.6)
Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets-&gt;tf-models-official-&gt;object-detection==0.1) (1.1.0)
Requirement already satisfied: importlib-resources; python_version &lt; &quot;3.9&quot; in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets-&gt;tf-models-official-&gt;object-detection==0.1) (5.1.4)
Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets-&gt;tf-models-official-&gt;object-detection==0.1) (2.3)
Requirement already satisfied: attrs&gt;=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets-&gt;tf-models-official-&gt;object-detection==0.1) (21.2.0)
Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets-&gt;tf-models-official-&gt;object-detection==0.1) (1.0.0)
Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow&gt;=2.5.0-&gt;tf-models-official-&gt;object-detection==0.1) (0.2.0)
Collecting tensorflow-estimator&lt;2.6.0,&gt;=2.5.0rc0
  Downloading https://files.pythonhosted.org/packages/ec/78/b27f73e923becc6e79e18fe112cf75e3200d1ee35b0dba8fa46181bce56c/tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462kB)
Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow&gt;=2.5.0-&gt;tf-models-official-&gt;object-detection==0.1) (1.12)
Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow&gt;=2.5.0-&gt;tf-models-official-&gt;object-detection==0.1) (0.36.2)
Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow&gt;=2.5.0-&gt;tf-models-official-&gt;object-detection==0.1) (1.12.1)
Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow&gt;=2.5.0-&gt;tf-models-official-&gt;object-detection==0.1) (3.3.0)
Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow&gt;=2.5.0-&gt;tf-models-official-&gt;object-detection==0.1) (1.1.2)
Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow&gt;=2.5.0-&gt;tf-models-official-&gt;object-detection==0.1) (1.6.3)
Collecting h5py~=3.1.0
  Downloading https://files.pythonhosted.org/packages/9d/74/9eae2bedd8201ab464308f42c601a12d79727a1c87f0c867fdefb212c6cf/h5py-3.1.0-cp37-cp37m-manylinux1_x86_64.whl (4.0MB)
Collecting tensorboard~=2.5
  Downloading https://files.pythonhosted.org/packages/44/f5/7feea02a3fb54d5db827ac4b822a7ba8933826b36de21880518250b8733a/tensorboard-2.5.0-py3-none-any.whl (6.0MB)
Collecting gast==0.4.0
  Downloading https://files.pythonhosted.org/packages/b6/48/583c032b79ae5b3daa02225a675aeb673e58d2cb698e78510feceb11958c/gast-0.4.0-py3-none-any.whl
Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow&gt;=2.5.0-&gt;tf-models-official-&gt;object-detection==0.1) (2.5.0.dev2021032900)
Requirement already satisfied: scikit-learn&gt;=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval-&gt;tf-models-official-&gt;object-detection==0.1) (0.22.2.post1)
Requirement already satisfied: google-cloud-core&lt;2.0dev,&gt;=1.0.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery&gt;=0.31.0-&gt;tf-models-official-&gt;object-detection==0.1) (1.0.3)
Requirement already satisfied: google-resumable-media!=0.4.0,&lt;0.5.0dev,&gt;=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery&gt;=0.31.0-&gt;tf-models-official-&gt;object-detection==0.1) (0.4.1)
Collecting portalocker==2.0.0
  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl
Requirement already satisfied: uritemplate&lt;4dev,&gt;=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client&gt;=1.6.7-&gt;tf-models-official-&gt;object-detection==0.1) (3.0.1)
Requirement already satisfied: google-auth&gt;=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client&gt;=1.6.7-&gt;tf-models-official-&gt;object-detection==0.1) (1.31.0)
Requirement already satisfied: google-auth-httplib2&gt;=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client&gt;=1.6.7-&gt;tf-models-official-&gt;object-detection==0.1) (0.0.4)
Requirement already satisfied: google-api-core&lt;2dev,&gt;=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client&gt;=1.6.7-&gt;tf-models-official-&gt;object-detection==0.1) (1.26.3)
Requirement already satisfied: text-unidecode&gt;=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify-&gt;kaggle&gt;=1.3.9-&gt;tf-models-official-&gt;object-detection==0.1) (1.3)
Requirement already satisfied: zipp&gt;=3.1.0; python_version &lt; &quot;3.10&quot; in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version &lt; &quot;3.9&quot;-&gt;tensorflow-datasets-&gt;tf-models-official-&gt;object-detection==0.1) (3.4.1)
Requirement already satisfied: googleapis-common-protos&lt;2,&gt;=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata-&gt;tensorflow-datasets-&gt;tf-models-official-&gt;object-detection==0.1) (1.53.0)
Requirement already satisfied: cached-property; python_version &lt; &quot;3.8&quot; in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0-&gt;tensorflow&gt;=2.5.0-&gt;tf-models-official-&gt;object-detection==0.1) (1.5.2)
Requirement already satisfied: tensorboard-data-server&lt;0.7.0,&gt;=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5-&gt;tensorflow&gt;=2.5.0-&gt;tf-models-official-&gt;object-detection==0.1) (0.6.1)
Requirement already satisfied: google-auth-oauthlib&lt;0.5,&gt;=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5-&gt;tensorflow&gt;=2.5.0-&gt;tf-models-official-&gt;object-detection==0.1) (0.4.4)
Requirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5-&gt;tensorflow&gt;=2.5.0-&gt;tf-models-official-&gt;object-detection==0.1) (1.8.0)
Requirement already satisfied: markdown&gt;=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5-&gt;tensorflow&gt;=2.5.0-&gt;tf-models-official-&gt;object-detection==0.1) (3.3.4)
Requirement already satisfied: werkzeug&gt;=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5-&gt;tensorflow&gt;=2.5.0-&gt;tf-models-official-&gt;object-detection==0.1) (1.0.1)
Requirement already satisfied: joblib&gt;=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn&gt;=0.21.3-&gt;seqeval-&gt;tf-models-official-&gt;object-detection==0.1) (1.0.1)
Requirement already satisfied: cachetools&lt;5.0,&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth&gt;=1.16.0-&gt;google-api-python-client&gt;=1.6.7-&gt;tf-models-official-&gt;object-detection==0.1) (4.2.2)
Requirement already satisfied: packaging&gt;=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core&lt;2dev,&gt;=1.21.0-&gt;google-api-python-client&gt;=1.6.7-&gt;tf-models-official-&gt;object-detection==0.1) (20.9)
Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard~=2.5-&gt;tensorflow&gt;=2.5.0-&gt;tf-models-official-&gt;object-detection==0.1) (1.3.0)
Requirement already satisfied: importlib-metadata; python_version &lt; &quot;3.8&quot; in /usr/local/lib/python3.7/dist-packages (from markdown&gt;=2.6.8-&gt;tensorboard~=2.5-&gt;tensorflow&gt;=2.5.0-&gt;tf-models-official-&gt;object-detection==0.1) (4.5.0)
Requirement already satisfied: oauthlib&gt;=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard~=2.5-&gt;tensorflow&gt;=2.5.0-&gt;tf-models-official-&gt;object-detection==0.1) (3.1.1)
Building wheels for collected packages: object-detection, avro-python3, dill, future, seqeval, py-cpuinfo
  Building wheel for object-detection (setup.py): started
  Building wheel for object-detection (setup.py): finished with status &#39;done&#39;
  Created wheel for object-detection: filename=object_detection-0.1-cp37-none-any.whl size=1654779 sha256=d1a8f845b09508702c2b1bd1506215a83c879cfc8b639efa36d8ac46a906ce2c
  Stored in directory: /tmp/pip-ephem-wheel-cache-p9kg4spf/wheels/94/49/4b/39b051683087a22ef7e80ec52152a27249d1a644ccf4e442ea
  Building wheel for avro-python3 (setup.py): started
  Building wheel for avro-python3 (setup.py): finished with status &#39;done&#39;
  Created wheel for avro-python3: filename=avro_python3-1.10.2-cp37-none-any.whl size=44011 sha256=14dc5817d71afabbfc5bdb8e982dab3e4e409b25734e90871e1860e9aaa600d0
  Stored in directory: /root/.cache/pip/wheels/ee/ee/18/c466221ca6900e3efce2f4ea9c329288808679aecdcb2838d3
  Building wheel for dill (setup.py): started
  Building wheel for dill (setup.py): finished with status &#39;done&#39;
  Created wheel for dill: filename=dill-0.3.1.1-cp37-none-any.whl size=78545 sha256=231757d8c496ad9adce61d5880dc8bea7eecb4762ef5090d884518ae3bfa41c4
  Stored in directory: /root/.cache/pip/wheels/59/b1/91/f02e76c732915c4015ab4010f3015469866c1eb9b14058d8e7
  Building wheel for future (setup.py): started
  Building wheel for future (setup.py): finished with status &#39;done&#39;
  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491070 sha256=c4a5f057c20eac16009a1855c0f6c1d3304b3c8c91d8adcdca8d7351d1627244
  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e
  Building wheel for seqeval (setup.py): started
  Building wheel for seqeval (setup.py): finished with status &#39;done&#39;
  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16184 sha256=3850d6ff2de0e16d3cbb830fdde28302dac2a6f4c8b0c5d25c60a3ceb7d7cd4d
  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f
  Building wheel for py-cpuinfo (setup.py): started
  Building wheel for py-cpuinfo (setup.py): finished with status &#39;done&#39;
  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-cp37-none-any.whl size=22258 sha256=c786e31ff7d5bbb3a8295901d3b9ad57e12a5f3b2acc48d1bcb9f7fceed4c769
  Stored in directory: /root/.cache/pip/wheels/2e/15/f5/aa2a056d223903b52cf4870134e3a01df0c723816835dd08db
Successfully built object-detection avro-python3 dill future seqeval py-cpuinfo
Installing collected packages: avro-python3, requests, hdfs, fastavro, dill, future, apache-beam, tf-slim, lvis, pyyaml, tensorflow-addons, tensorflow-model-optimization, tensorflow-estimator, h5py, tensorboard, gast, tensorflow, seqeval, opencv-python-headless, portalocker, sacrebleu, sentencepiece, py-cpuinfo, tf-models-official, object-detection
  Found existing installation: requests 2.23.0
    Uninstalling requests-2.23.0:
      Successfully uninstalled requests-2.23.0
  Found existing installation: dill 0.3.4
    Uninstalling dill-0.3.4:
      Successfully uninstalled dill-0.3.4
  Found existing installation: future 0.16.0
    Uninstalling future-0.16.0:
      Successfully uninstalled future-0.16.0
  Found existing installation: PyYAML 3.13
    Uninstalling PyYAML-3.13:
      Successfully uninstalled PyYAML-3.13
  Found existing installation: tensorflow-estimator 2.2.0
    Uninstalling tensorflow-estimator-2.2.0:
      Successfully uninstalled tensorflow-estimator-2.2.0
  Found existing installation: h5py 2.10.0
    Uninstalling h5py-2.10.0:
      Successfully uninstalled h5py-2.10.0
  Found existing installation: tensorboard 2.2.2
    Uninstalling tensorboard-2.2.2:
      Successfully uninstalled tensorboard-2.2.2
  Found existing installation: gast 0.3.3
    Uninstalling gast-0.3.3:
      Successfully uninstalled gast-0.3.3
  Found existing installation: tensorflow 2.2.0
    Uninstalling tensorflow-2.2.0:
      Successfully uninstalled tensorflow-2.2.0
Successfully installed apache-beam-2.30.0 avro-python3-1.10.2 dill-0.3.1.1 fastavro-1.4.1 future-0.18.2 gast-0.4.0 h5py-3.1.0 hdfs-2.6.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.2.54 portalocker-2.0.0 py-cpuinfo-8.0.0 pyyaml-5.4.1 requests-2.25.1 sacrebleu-1.5.1 sentencepiece-0.1.96 seqeval-1.2.2 tensorboard-2.5.0 tensorflow-2.5.0 tensorflow-addons-0.13.0 tensorflow-estimator-2.5.0 tensorflow-model-optimization-0.6.0 tf-models-official-2.5.0 tf-slim-1.1.0


ERROR: multiprocess 0.70.12.2 has requirement dill&gt;=0.3.4, but you&#39;ll have dill 0.3.1.1 which is incompatible.
ERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you&#39;ll have requests 2.25.1 which is incompatible.
ERROR: datascience 0.10.6 has requirement folium==0.2.1, but you&#39;ll have folium 0.8.3 which is incompatible.
ERROR: apache-beam 2.30.0 has requirement avro-python3!=1.9.2,&lt;1.10.0,&gt;=1.8.1, but you&#39;ll have avro-python3 1.10.2 which is incompatible.
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> imageio</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> scipy.misc</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> six <span class="keyword">import</span> BytesIO</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image, ImageDraw, ImageFont</span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> display, Javascript</span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> Image <span class="keyword">as</span> IPyImage</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> object_detection.utils <span class="keyword">import</span> label_map_util</span><br><span class="line"><span class="keyword">from</span> object_detection.utils <span class="keyword">import</span> config_util</span><br><span class="line"><span class="keyword">from</span> object_detection.utils <span class="keyword">import</span> visualization_utils <span class="keyword">as</span> viz_utils</span><br><span class="line"><span class="keyword">from</span> object_detection.utils <span class="keyword">import</span> colab_utils</span><br><span class="line"><span class="keyword">from</span> object_detection.builders <span class="keyword">import</span> model_builder</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>

<h1 id="Utilities"><a href="#Utilities" class="headerlink" title="Utilities"></a>Utilities</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_image_into_numpy_array</span>(<span class="params">path</span>):</span></span><br><span class="line">  <span class="string">&quot;&quot;&quot;Load an image from file into a numpy array.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Puts image into numpy array to feed into tensorflow graph.</span></span><br><span class="line"><span class="string">  Note that by convention we put it into a numpy array with shape</span></span><br><span class="line"><span class="string">  (height, width, channels), where channels=3 for RGB.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    path: a file path.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">    uint8 numpy array with shape (img_height, img_width, 3)</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">  img_data = tf.io.gfile.GFile(path, <span class="string">&#x27;rb&#x27;</span>).read()</span><br><span class="line">  image = Image.<span class="built_in">open</span>(BytesIO(img_data))</span><br><span class="line">  (im_width, im_height) = image.size</span><br><span class="line">  <span class="keyword">return</span> np.array(image.getdata()).reshape(</span><br><span class="line">      (im_height, im_width, <span class="number">3</span>)).astype(np.uint8)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_detections</span>(<span class="params">image_np,</span></span></span><br><span class="line"><span class="function"><span class="params">                    boxes,</span></span></span><br><span class="line"><span class="function"><span class="params">                    classes,</span></span></span><br><span class="line"><span class="function"><span class="params">                    scores,</span></span></span><br><span class="line"><span class="function"><span class="params">                    category_index,</span></span></span><br><span class="line"><span class="function"><span class="params">                    figsize=(<span class="params"><span class="number">12</span>, <span class="number">16</span></span>),</span></span></span><br><span class="line"><span class="function"><span class="params">                    image_name=<span class="literal">None</span></span>):</span></span><br><span class="line">  <span class="string">&quot;&quot;&quot;Wrapper function to visualize detections.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    image_np: uint8 numpy array with shape (img_height, img_width, 3)</span></span><br><span class="line"><span class="string">    boxes: a numpy array of shape [N, 4]</span></span><br><span class="line"><span class="string">    classes: a numpy array of shape [N]. Note that class indices are 1-based,</span></span><br><span class="line"><span class="string">      and match the keys in the label map.</span></span><br><span class="line"><span class="string">    scores: a numpy array of shape [N] or None.  If scores=None, then</span></span><br><span class="line"><span class="string">      this function assumes that the boxes to be plotted are groundtruth</span></span><br><span class="line"><span class="string">      boxes and plot all boxes as black with no classes or scores.</span></span><br><span class="line"><span class="string">    category_index: a dict containing category dictionaries (each holding</span></span><br><span class="line"><span class="string">      category index `id` and category name `name`) keyed by category indices.</span></span><br><span class="line"><span class="string">    figsize: size for the figure.</span></span><br><span class="line"><span class="string">    image_name: a name for the image file.</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">  image_np_with_annotations = image_np.copy()</span><br><span class="line">  viz_utils.visualize_boxes_and_labels_on_image_array(</span><br><span class="line">      image_np_with_annotations,</span><br><span class="line">      boxes,</span><br><span class="line">      classes,</span><br><span class="line">      scores,</span><br><span class="line">      category_index,</span><br><span class="line">      use_normalized_coordinates=<span class="literal">True</span>,</span><br><span class="line">      min_score_thresh=<span class="number">0.8</span>)</span><br><span class="line">  <span class="keyword">if</span> image_name:</span><br><span class="line">    plt.imsave(image_name, image_np_with_annotations)</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    plt.imshow(image_np_with_annotations)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="Rubber-Ducky-data"><a href="#Rubber-Ducky-data" class="headerlink" title="Rubber Ducky data"></a>Rubber Ducky data</h1><p>We will start with some toy (literally) data consisting of 5 images of a rubber<br>ducky.  Note that the <a target="_blank" rel="noopener" href="https://cocodataset.org/#explore">coco</a> dataset contains a number of animals, but notably, it does <em>not</em> contain rubber duckies (or even ducks for that matter), so this is a novel class.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load images and visualize</span></span><br><span class="line">train_image_dir = <span class="string">&#x27;models/research/object_detection/test_images/ducky/train/&#x27;</span></span><br><span class="line">train_images_np = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">6</span>):</span><br><span class="line">  image_path = os.path.join(train_image_dir, <span class="string">&#x27;robertducky&#x27;</span> + <span class="built_in">str</span>(i) + <span class="string">&#x27;.jpg&#x27;</span>)</span><br><span class="line">  train_images_np.append(load_image_into_numpy_array(image_path))</span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.grid&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;xtick.labelsize&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;ytick.labelsize&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;xtick.top&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;xtick.bottom&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;ytick.left&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;ytick.right&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = [<span class="number">14</span>, <span class="number">7</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> idx, train_image_np <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_images_np):</span><br><span class="line">  plt.subplot(<span class="number">2</span>, <span class="number">3</span>, idx+<span class="number">1</span>)</span><br><span class="line">  plt.imshow(train_image_np)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/2021/06/19/fine_tune_in_tf2x/interactive_eager_few_shot_od_training_colab_9_0.png" alt="png"></p>
<h1 id="Annotate-images-with-bounding-boxes"><a href="#Annotate-images-with-bounding-boxes" class="headerlink" title="Annotate images with bounding boxes"></a>Annotate images with bounding boxes</h1><p>In this cell you will annotate the rubber duckies ‚Äî draw a box around the rubber ducky in each image; click <code>next image</code> to go to the next image and <code>submit</code> when there are no more images.</p>
<p>If you‚Äôd like to skip the manual annotation step, we totally understand.  In this case, simply skip this cell and run the next cell instead, where we‚Äôve prepopulated the groundtruth with pre-annotated bounding boxes.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gt_boxes = []</span><br><span class="line">colab_utils.annotate(train_images_np, box_storage_pointer=gt_boxes)</span><br></pre></td></tr></table></figure>

<h1 id="In-case-you-didn‚Äôt-want-to-label‚Ä¶"><a href="#In-case-you-didn‚Äôt-want-to-label‚Ä¶" class="headerlink" title="In case you didn‚Äôt want to label‚Ä¶"></a>In case you didn‚Äôt want to label‚Ä¶</h1><p>Run this cell only if you didn‚Äôt annotate anything above and<br>would prefer to just use our preannotated boxes.  Don‚Äôt forget<br>to uncomment.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># gt_boxes = [</span></span><br><span class="line"><span class="comment">#             np.array([[0.436, 0.591, 0.629, 0.712]], dtype=np.float32),</span></span><br><span class="line"><span class="comment">#             np.array([[0.539, 0.583, 0.73, 0.71]], dtype=np.float32),</span></span><br><span class="line"><span class="comment">#             np.array([[0.464, 0.414, 0.626, 0.548]], dtype=np.float32),</span></span><br><span class="line"><span class="comment">#             np.array([[0.313, 0.308, 0.648, 0.526]], dtype=np.float32),</span></span><br><span class="line"><span class="comment">#             np.array([[0.256, 0.444, 0.484, 0.629]], dtype=np.float32)</span></span><br><span class="line"><span class="comment"># ]</span></span><br></pre></td></tr></table></figure>

<h1 id="Prepare-data-for-training"><a href="#Prepare-data-for-training" class="headerlink" title="Prepare data for training"></a>Prepare data for training</h1><p>Below we add the class annotations (for simplicity, we assume a single class in this colab; though it should be straightforward to extend this to handle multiple classes).  We also convert everything to the format that the training<br>loop below expects (e.g., everything converted to tensors, classes converted to one-hot representations, etc.).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># By convention, our non-background classes start counting at 1.  Given</span></span><br><span class="line"><span class="comment"># that we will be predicting just one class, we will therefore assign it a</span></span><br><span class="line"><span class="comment"># `class id` of 1.</span></span><br><span class="line">duck_class_id = <span class="number">1</span></span><br><span class="line">num_classes = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">category_index = &#123;duck_class_id: &#123;<span class="string">&#x27;id&#x27;</span>: duck_class_id, <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;rubber_ducky&#x27;</span>&#125;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert class labels to one-hot; convert everything to tensors.</span></span><br><span class="line"><span class="comment"># The `label_id_offset` here shifts all classes by a certain number of indices;</span></span><br><span class="line"><span class="comment"># we do this here so that the model receives one-hot labels where non-background</span></span><br><span class="line"><span class="comment"># classes start counting at the zeroth index.  This is ordinarily just handled</span></span><br><span class="line"><span class="comment"># automatically in our training binaries, but we need to reproduce it here.</span></span><br><span class="line">label_id_offset = <span class="number">1</span></span><br><span class="line">train_image_tensors = []</span><br><span class="line">gt_classes_one_hot_tensors = []</span><br><span class="line">gt_box_tensors = []</span><br><span class="line"><span class="keyword">for</span> (train_image_np, gt_box_np) <span class="keyword">in</span> <span class="built_in">zip</span>(</span><br><span class="line">    train_images_np, gt_boxes):</span><br><span class="line">  train_image_tensors.append(tf.expand_dims(tf.convert_to_tensor(</span><br><span class="line">      train_image_np, dtype=tf.float32), axis=<span class="number">0</span>))</span><br><span class="line">  gt_box_tensors.append(tf.convert_to_tensor(gt_box_np, dtype=tf.float32))</span><br><span class="line">  zero_indexed_groundtruth_classes = tf.convert_to_tensor(</span><br><span class="line">      np.ones(shape=[gt_box_np.shape[<span class="number">0</span>]], dtype=np.int32) - label_id_offset)</span><br><span class="line">  gt_classes_one_hot_tensors.append(tf.one_hot(</span><br><span class="line">      zero_indexed_groundtruth_classes, num_classes))</span><br><span class="line">print(<span class="string">&#x27;Done prepping data.&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>Done prepping data.
</code></pre>
<h1 id="Let‚Äôs-just-visualize-the-rubber-duckies-as-a-sanity-check"><a href="#Let‚Äôs-just-visualize-the-rubber-duckies-as-a-sanity-check" class="headerlink" title="Let‚Äôs just visualize the rubber duckies as a sanity check"></a>Let‚Äôs just visualize the rubber duckies as a sanity check</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">dummy_scores = np.array([<span class="number">1.0</span>], dtype=np.float32)  <span class="comment"># give boxes a score of 100%</span></span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">30</span>, <span class="number">15</span>))</span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">  plt.subplot(<span class="number">2</span>, <span class="number">3</span>, idx+<span class="number">1</span>)</span><br><span class="line">  plot_detections(</span><br><span class="line">      train_images_np[idx],</span><br><span class="line">      gt_boxes[idx],</span><br><span class="line">      np.ones(shape=[gt_boxes[idx].shape[<span class="number">0</span>]], dtype=np.int32),</span><br><span class="line">      dummy_scores, category_index)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/2021/06/19/fine_tune_in_tf2x/interactive_eager_few_shot_od_training_colab_17_0.png" alt="png"></p>
<h1 id="Create-model-and-restore-weights-for-all-but-last-layer"><a href="#Create-model-and-restore-weights-for-all-but-last-layer" class="headerlink" title="Create model and restore weights for all but last layer"></a>Create model and restore weights for all but last layer</h1><p>In this cell we build a single stage detection architecture (RetinaNet) and restore all but the classification layer at the top (which will be automatically randomly initialized).</p>
<p>For simplicity, we have hardcoded a number of things in this colab for the specific RetinaNet architecture at hand (including assuming that the image size will always be 640x640), however it is not difficult to generalize to other model configurations.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Download the checkpoint and put it into models&#x2F;research&#x2F;object_detection&#x2F;test_data&#x2F;</span><br><span class="line"></span><br><span class="line">!wget http:&#x2F;&#x2F;download.tensorflow.org&#x2F;models&#x2F;object_detection&#x2F;tf2&#x2F;20200711&#x2F;ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz</span><br><span class="line">!tar -xf ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz</span><br><span class="line">!mv ssd_resnet50_v1_fpn_640x640_coco17_tpu-8&#x2F;checkpoint models&#x2F;research&#x2F;object_detection&#x2F;test_data&#x2F;</span><br></pre></td></tr></table></figure>

<pre><code>--2021-06-19 06:13:24--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz
Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.142.128, 2607:f8b0:400e:c06::80
Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.142.128|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 244817203 (233M) [application/x-tar]
Saving to: ‚Äòssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz‚Äô

ssd_resnet50_v1_fpn 100%[===================&gt;] 233.48M   164MB/s    in 1.4s    

2021-06-19 06:13:25 (164 MB/s) - ‚Äòssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz‚Äô saved [244817203/244817203]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.backend.clear_session()</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;Building model and restoring weights for fine-tuning...&#x27;</span>, flush=<span class="literal">True</span>)</span><br><span class="line">num_classes = <span class="number">1</span></span><br><span class="line">pipeline_config = <span class="string">&#x27;models/research/object_detection/configs/tf2/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.config&#x27;</span></span><br><span class="line">checkpoint_path = <span class="string">&#x27;models/research/object_detection/test_data/checkpoint/ckpt-0&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Load pipeline config and build a detection model.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Since we are working off of a COCO architecture which predicts 90</span></span><br><span class="line"><span class="comment"># class slots by default, we override the `num_classes` field here to be just</span></span><br><span class="line"><span class="comment"># one (for our new rubber ducky class).</span></span><br><span class="line">configs = config_util.get_configs_from_pipeline_file(pipeline_config)</span><br><span class="line">model_config = configs[<span class="string">&#x27;model&#x27;</span>]</span><br><span class="line">model_config.ssd.num_classes = num_classes</span><br><span class="line">model_config.ssd.freeze_batchnorm = <span class="literal">True</span></span><br><span class="line">detection_model = model_builder.build(</span><br><span class="line">      model_config=model_config, is_training=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set up object-based checkpoint restore --- RetinaNet has two prediction</span></span><br><span class="line"><span class="comment"># `heads` --- one for classification, the other for box regression.  We will</span></span><br><span class="line"><span class="comment"># restore the box regression head but initialize the classification head</span></span><br><span class="line"><span class="comment"># from scratch (we show the omission below by commenting out the line that</span></span><br><span class="line"><span class="comment"># we would add if we wanted to restore both heads)</span></span><br><span class="line">fake_box_predictor = tf.compat.v2.train.Checkpoint(</span><br><span class="line">    _base_tower_layers_for_heads=detection_model._box_predictor._base_tower_layers_for_heads,</span><br><span class="line">    <span class="comment"># _prediction_heads=detection_model._box_predictor._prediction_heads,</span></span><br><span class="line">    <span class="comment">#    (i.e., the classification head that we *will not* restore)</span></span><br><span class="line">    _box_prediction_head=detection_model._box_predictor._box_prediction_head,</span><br><span class="line">    )</span><br><span class="line">fake_model = tf.compat.v2.train.Checkpoint(</span><br><span class="line">          _feature_extractor=detection_model._feature_extractor,</span><br><span class="line">          _box_predictor=fake_box_predictor)</span><br><span class="line">ckpt = tf.compat.v2.train.Checkpoint(model=fake_model)</span><br><span class="line">ckpt.restore(checkpoint_path).expect_partial()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run model through a dummy image so that variables are created</span></span><br><span class="line">image, shapes = detection_model.preprocess(tf.zeros([<span class="number">1</span>, <span class="number">640</span>, <span class="number">640</span>, <span class="number">3</span>]))</span><br><span class="line">prediction_dict = detection_model.predict(image, shapes)</span><br><span class="line">_ = detection_model.postprocess(prediction_dict, shapes)</span><br><span class="line">print(<span class="string">&#x27;Weights restored!&#x27;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Building model and restoring weights for fine-tuning...
Weights restored!
</code></pre>
<h1 id="Eager-mode-custom-training-loop"><a href="#Eager-mode-custom-training-loop" class="headerlink" title="Eager mode custom training loop"></a>Eager mode custom training loop</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.backend.set_learning_phase(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># These parameters can be tuned; since our training set has 5 images</span></span><br><span class="line"><span class="comment"># it doesn&#x27;t make sense to have a much larger batch size, though we could</span></span><br><span class="line"><span class="comment"># fit more examples in memory if we wanted to.</span></span><br><span class="line">batch_size = <span class="number">4</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">num_batches = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Select variables in top layers to fine-tune.</span></span><br><span class="line">trainable_variables = detection_model.trainable_variables</span><br><span class="line">to_fine_tune = []</span><br><span class="line">prefixes_to_train = [</span><br><span class="line">  <span class="string">&#x27;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> var <span class="keyword">in</span> trainable_variables:</span><br><span class="line">  <span class="keyword">if</span> <span class="built_in">any</span>([var.name.startswith(prefix) <span class="keyword">for</span> prefix <span class="keyword">in</span> prefixes_to_train]):</span><br><span class="line">    to_fine_tune.append(var)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set up forward + backward pass for a single train step.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_model_train_step_function</span>(<span class="params">model, optimizer, vars_to_fine_tune</span>):</span></span><br><span class="line">  <span class="string">&quot;&quot;&quot;Get a tf.function for training step.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Use tf.function for a bit of speed.</span></span><br><span class="line">  <span class="comment"># Comment out the tf.function decorator if you want the inside of the</span></span><br><span class="line">  <span class="comment"># function to run eagerly.</span></span><br><span class="line"><span class="meta">  @tf.function</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">train_step_fn</span>(<span class="params">image_tensors,</span></span></span><br><span class="line"><span class="function"><span class="params">                    groundtruth_boxes_list,</span></span></span><br><span class="line"><span class="function"><span class="params">                    groundtruth_classes_list</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;A single training iteration.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">      image_tensors: A list of [1, height, width, 3] Tensor of type tf.float32.</span></span><br><span class="line"><span class="string">        Note that the height and width can vary across images, as they are</span></span><br><span class="line"><span class="string">        reshaped within this function to be 640x640.</span></span><br><span class="line"><span class="string">      groundtruth_boxes_list: A list of Tensors of shape [N_i, 4] with type</span></span><br><span class="line"><span class="string">        tf.float32 representing groundtruth boxes for each image in the batch.</span></span><br><span class="line"><span class="string">      groundtruth_classes_list: A list of Tensors of shape [N_i, num_classes]</span></span><br><span class="line"><span class="string">        with type tf.float32 representing groundtruth boxes for each image in</span></span><br><span class="line"><span class="string">        the batch.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">      A scalar tensor representing the total loss for the input batch.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    shapes = tf.constant(batch_size * [[<span class="number">640</span>, <span class="number">640</span>, <span class="number">3</span>]], dtype=tf.int32)</span><br><span class="line">    model.provide_groundtruth(</span><br><span class="line">        groundtruth_boxes_list=groundtruth_boxes_list,</span><br><span class="line">        groundtruth_classes_list=groundtruth_classes_list)</span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">      preprocessed_images = tf.concat(</span><br><span class="line">          [detection_model.preprocess(image_tensor)[<span class="number">0</span>]</span><br><span class="line">           <span class="keyword">for</span> image_tensor <span class="keyword">in</span> image_tensors], axis=<span class="number">0</span>)</span><br><span class="line">      prediction_dict = model.predict(preprocessed_images, shapes)</span><br><span class="line">      losses_dict = model.loss(prediction_dict, shapes)</span><br><span class="line">      total_loss = losses_dict[<span class="string">&#x27;Loss/localization_loss&#x27;</span>] + losses_dict[<span class="string">&#x27;Loss/classification_loss&#x27;</span>]</span><br><span class="line">      gradients = tape.gradient(total_loss, vars_to_fine_tune)</span><br><span class="line">      optimizer.apply_gradients(<span class="built_in">zip</span>(gradients, vars_to_fine_tune))</span><br><span class="line">    <span class="keyword">return</span> total_loss</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> train_step_fn</span><br><span class="line"></span><br><span class="line">optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=<span class="number">0.9</span>)</span><br><span class="line">train_step_fn = get_model_train_step_function(</span><br><span class="line">    detection_model, optimizer, to_fine_tune)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;Start fine-tuning!&#x27;</span>, flush=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(num_batches):</span><br><span class="line">  <span class="comment"># Grab keys for a random subset of examples</span></span><br><span class="line">  all_keys = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="built_in">len</span>(train_images_np)))</span><br><span class="line">  random.shuffle(all_keys)</span><br><span class="line">  example_keys = all_keys[:batch_size]</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Note that we do not do data augmentation in this demo.  If you want a</span></span><br><span class="line">  <span class="comment"># a fun exercise, we recommend experimenting with random horizontal flipping</span></span><br><span class="line">  <span class="comment"># and random cropping :)</span></span><br><span class="line">  gt_boxes_list = [gt_box_tensors[key] <span class="keyword">for</span> key <span class="keyword">in</span> example_keys]</span><br><span class="line">  gt_classes_list = [gt_classes_one_hot_tensors[key] <span class="keyword">for</span> key <span class="keyword">in</span> example_keys]</span><br><span class="line">  image_tensors = [train_image_tensors[key] <span class="keyword">for</span> key <span class="keyword">in</span> example_keys]</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Training step (forward pass + backwards pass)</span></span><br><span class="line">  total_loss = train_step_fn(image_tensors, gt_boxes_list, gt_classes_list)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> idx % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">    print(<span class="string">&#x27;batch &#x27;</span> + <span class="built_in">str</span>(idx) + <span class="string">&#x27; of &#x27;</span> + <span class="built_in">str</span>(num_batches)</span><br><span class="line">    + <span class="string">&#x27;, loss=&#x27;</span> +  <span class="built_in">str</span>(total_loss.numpy()), flush=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;Done fine-tuning!&#x27;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Start fine-tuning!


/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:435: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.
  warnings.warn(&#39;`tf.keras.backend.set_learning_phase` is deprecated and &#39;


batch 0 of 100, loss=1.3292191
batch 10 of 100, loss=0.22281
batch 20 of 100, loss=0.037707128
batch 30 of 100, loss=0.023981009
batch 40 of 100, loss=0.011248456
batch 50 of 100, loss=0.0075090434
batch 60 of 100, loss=0.006269014
batch 70 of 100, loss=0.00528784
batch 80 of 100, loss=0.003169425
batch 90 of 100, loss=0.0042762198
Done fine-tuning!
</code></pre>
<h1 id="Load-test-images-and-run-inference-with-new-model"><a href="#Load-test-images-and-run-inference-with-new-model" class="headerlink" title="Load test images and run inference with new model!"></a>Load test images and run inference with new model!</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">test_image_dir = <span class="string">&#x27;models/research/object_detection/test_images/ducky/test/&#x27;</span></span><br><span class="line">test_images_np = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">50</span>):</span><br><span class="line">  image_path = os.path.join(test_image_dir, <span class="string">&#x27;out&#x27;</span> + <span class="built_in">str</span>(i) + <span class="string">&#x27;.jpg&#x27;</span>)</span><br><span class="line">  test_images_np.append(np.expand_dims(</span><br><span class="line">      load_image_into_numpy_array(image_path), axis=<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Again, uncomment this decorator if you want to run inference eagerly</span></span><br><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">detect</span>(<span class="params">input_tensor</span>):</span></span><br><span class="line">  <span class="string">&quot;&quot;&quot;Run detection on an input image.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    input_tensor: A [1, height, width, 3] Tensor of type tf.float32.</span></span><br><span class="line"><span class="string">      Note that height and width can be anything since the image will be</span></span><br><span class="line"><span class="string">      immediately resized according to the needs of the model within this</span></span><br><span class="line"><span class="string">      function.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">    A dict containing 3 Tensors (`detection_boxes`, `detection_classes`,</span></span><br><span class="line"><span class="string">      and `detection_scores`).</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">  preprocessed_image, shapes = detection_model.preprocess(input_tensor)</span><br><span class="line">  prediction_dict = detection_model.predict(preprocessed_image, shapes)</span><br><span class="line">  <span class="keyword">return</span> detection_model.postprocess(prediction_dict, shapes)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Note that the first frame will trigger tracing of the tf.function, which will</span></span><br><span class="line"><span class="comment"># take some time, after which inference should be fast.</span></span><br><span class="line"></span><br><span class="line">label_id_offset = <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(test_images_np)):</span><br><span class="line">  input_tensor = tf.convert_to_tensor(test_images_np[i], dtype=tf.float32)</span><br><span class="line">  detections = detect(input_tensor)</span><br><span class="line"></span><br><span class="line">  plot_detections(</span><br><span class="line">      test_images_np[i][<span class="number">0</span>],</span><br><span class="line">      detections[<span class="string">&#x27;detection_boxes&#x27;</span>][<span class="number">0</span>].numpy(),</span><br><span class="line">      detections[<span class="string">&#x27;detection_classes&#x27;</span>][<span class="number">0</span>].numpy().astype(np.uint32)</span><br><span class="line">      + label_id_offset,</span><br><span class="line">      detections[<span class="string">&#x27;detection_scores&#x27;</span>][<span class="number">0</span>].numpy(),</span><br><span class="line">      category_index, figsize=(<span class="number">15</span>, <span class="number">20</span>), image_name=<span class="string">&quot;gif_frame_&quot;</span> + (<span class="string">&#x27;%02d&#x27;</span> % i) + <span class="string">&quot;.jpg&quot;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">imageio.plugins.freeimage.download()</span><br><span class="line"></span><br><span class="line">anim_file = <span class="string">&#x27;duckies_test.gif&#x27;</span></span><br><span class="line"></span><br><span class="line">filenames = glob.glob(<span class="string">&#x27;gif_frame_*.jpg&#x27;</span>)</span><br><span class="line">filenames = <span class="built_in">sorted</span>(filenames)</span><br><span class="line">last = -<span class="number">1</span></span><br><span class="line">images = []</span><br><span class="line"><span class="keyword">for</span> filename <span class="keyword">in</span> filenames:</span><br><span class="line">  image = imageio.imread(filename)</span><br><span class="line">  images.append(image)</span><br><span class="line"></span><br><span class="line">imageio.mimsave(anim_file, images, <span class="string">&#x27;GIF-FI&#x27;</span>, fps=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">display(IPyImage(<span class="built_in">open</span>(anim_file, <span class="string">&#x27;rb&#x27;</span>).read()))</span><br></pre></td></tr></table></figure>

<pre><code>Imageio: &#39;libfreeimage-3.16.0-linux64.so&#39; was not found on your computer; downloading it now.
Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/freeimage/libfreeimage-3.16.0-linux64.so (4.6 MB)
  Done
File saved as /root/.imageio/freeimage/libfreeimage-3.16.0-linux64.so.
</code></pre>
<p><img src="/2021/06/19/fine_tune_in_tf2x/interactive_eager_few_shot_od_training_colab_25_1.gif" alt="png"></p>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>Êú¨Êñá‰ΩúËÄÖÔºö </strong>Young Times
  </li>
  <li class="post-copyright-link">
    <strong>Êú¨ÊñáÈìæÊé•Ôºö</strong>
    <a href="http://example.com/2021/06/19/fine_tune_in_tf2x/" title="Fine Tune in Tensorflow 2.x">http://example.com/2021/06/19/fine_tune_in_tf2x/</a>
  </li>
  <li class="post-copyright-license">
    <strong>ÁâàÊùÉÂ£∞ÊòéÔºö </strong>Êú¨ÂçöÂÆ¢ÊâÄÊúâÊñáÁ´†Èô§ÁâπÂà´Â£∞ÊòéÂ§ñÔºåÂùáÈááÁî® <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> ËÆ∏ÂèØÂçèËÆÆ„ÄÇËΩ¨ËΩΩËØ∑Ê≥®ÊòéÂá∫Â§ÑÔºÅ
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/" rel="tag"># Ëá™Âä®È©æÈ©∂</a>
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># Êú∫Âô®Â≠¶‰π†</a>
              <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"># Ê∑±Â∫¶Â≠¶‰π†</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/06/14/object_detection/" rel="prev" title="Object Detection">
      <i class="fa fa-chevron-left"></i> Object Detection
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          ÊñáÁ´†ÁõÆÂΩï
        </li>
        <li class="sidebar-nav-overview">
          Á´ôÁÇπÊ¶ÇËßà
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Eager-Few-Shot-Object-Detection-Colab"><span class="nav-number">1.</span> <span class="nav-text">Eager Few Shot Object Detection Colab</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Imports"><span class="nav-number">1.1.</span> <span class="nav-text">Imports</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Utilities"><span class="nav-number">2.</span> <span class="nav-text">Utilities</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Rubber-Ducky-data"><span class="nav-number">3.</span> <span class="nav-text">Rubber Ducky data</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Annotate-images-with-bounding-boxes"><span class="nav-number">4.</span> <span class="nav-text">Annotate images with bounding boxes</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#In-case-you-didn%E2%80%99t-want-to-label%E2%80%A6"><span class="nav-number">5.</span> <span class="nav-text">In case you didn‚Äôt want to label‚Ä¶</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Prepare-data-for-training"><span class="nav-number">6.</span> <span class="nav-text">Prepare data for training</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Let%E2%80%99s-just-visualize-the-rubber-duckies-as-a-sanity-check"><span class="nav-number">7.</span> <span class="nav-text">Let‚Äôs just visualize the rubber duckies as a sanity check</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Create-model-and-restore-weights-for-all-but-last-layer"><span class="nav-number">8.</span> <span class="nav-text">Create model and restore weights for all but last layer</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Eager-mode-custom-training-loop"><span class="nav-number">9.</span> <span class="nav-text">Eager mode custom training loop</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Load-test-images-and-run-inference-with-new-model"><span class="nav-number">10.</span> <span class="nav-text">Load test images and run inference with new model!</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Young Times"
      src="/images/header.jpg">
  <p class="site-author-name" itemprop="name">Young Times</p>
  <div class="site-description" itemprop="description">Ë∑ØË¶Å‰∏ÄÊ≠•‰∏ÄÊ≠•ÁöÑËµ∞</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">30</span>
          <span class="site-state-item-name">Êó•Âøó</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">ÂàÜÁ±ª</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">66</span>
        <span class="site-state-item-name">Ê†áÁ≠æ</span></a>
      </div>
  </nav>
</div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Young Times</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    <span title="Á´ôÁÇπÊÄªÂ≠óÊï∞">242k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Á´ôÁÇπÈòÖËØªÊó∂Èïø">3:40</span>
</div>

<span id="busuanzi_container_site_uv">
  Êú¨Á´ôËÆøÈóÆÊ¨°Êï∞Ôºö<span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
</span>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="ÊÄªËÆøÂÆ¢Èáè">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="ÊÄªËÆøÈóÆÈáè">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'hEvBR6pmxtoYkRhC3fnMB8Yq-gzGzoHsz',
      appKey     : 'nIkzvtLYb1avq32c9GYfgOOW',
      placeholder: "Please Leave Your Message Here...",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : 'zh-cn' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
